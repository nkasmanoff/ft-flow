{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import transformers\n",
    "from trl import SFTTrainer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "import os\n",
    "import json\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets transformers trl wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"NousResearch/hermes-function-calling-v1\", \"glaive_func_calling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "tools_list = []\n",
    "for tool in ds['train']['tools']:\n",
    "    if tool == 'null':\n",
    "        tools_list.append(None)\n",
    "        continue\n",
    "\n",
    "    # str fixes to convert to dict\n",
    "    tool = tool.replace('true','True')\n",
    "    tool = tool.replace('false','False')\n",
    "    tool = tool.replace('null','None')\n",
    "    tools_list.append(literal_eval(tool))   \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'get_stock_price',\n",
       "   'description': 'Get the current stock price',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'symbol': {'type': 'string',\n",
       "      'description': 'The stock symbol, e.g. AAPL'}},\n",
       "    'required': ['symbol']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'search_recipes',\n",
       "   'description': 'Search for recipes based on ingredients',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'ingredients': {'type': 'array',\n",
       "      'items': {'type': 'string'},\n",
       "      'description': 'The ingredients to be used in the recipes'}},\n",
       "    'required': ['ingredients']}}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools_list[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5209/5209 [00:20<00:00, 258.50it/s]\n"
     ]
    }
   ],
   "source": [
    "pydantic_schema = \"\"\"{'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}\"\"\"\n",
    "from tqdm import tqdm\n",
    "\n",
    "system_prompts = []\n",
    "for i in tqdm(range(len(ds['train']))):\n",
    "    if ds['train']['tools'][i] == 'null':\n",
    "        system_prompts.append(system_prompt)\n",
    "    else:\n",
    "        available_tools = tools_list[i]\n",
    "        system_prompt = f\"\"\"You are a function calling AI model.\n",
    "You are provided with function signatures within <tools></tools> XML tags.\n",
    "You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools:\n",
    "<tools>\n",
    "{available_tools}\n",
    "</tools>\n",
    "Use the following pydantic model json schema for each tool call you will make: \n",
    "{pydantic_schema}\n",
    "For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "<tool_call>\n",
    "{{tool_call}}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    "        system_prompts.append(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  To use as reference when creating tools in the future.\n",
    "\n",
    "custom_tools_list = [{'type': 'function',\n",
    "  'function': {'name': 'turn_on_lights',\n",
    "   'description': 'Turn the lights on',\n",
    "    'parameters': {}}},    \n",
    " {'type': 'function',\n",
    "  'function': {'name': 'get_news',\n",
    "   'description': 'Get the latest news',\n",
    "   'parameters': {'type': 'object',\n",
    "    'properties': {'category': {'type': 'string',\n",
    "      'description': 'The category of news, e.g. sports, politics'}},\n",
    "    'required': ['category']}}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column to dataset called system_prompt\n",
    "ds['train'] = ds['train'].add_column('system_prompt', system_prompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# Tokenizer Loading\n",
    "###################\n",
    "\n",
    "#checkpoint_path = \"HuggingFaceTB/SmolLM-1.7B-instruct\"\n",
    "checkpoint_path = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "tokenizer.model_max_length = 2048\n",
    "tokenizer.pad_token = \"<unk>\"  # note this is specific to smollm\n",
    "tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token )\n",
    "tokenizer.padding_side = 'right'\n",
    "# https://stackoverflow.com/questions/76446228/setting-padding-token-as-eos-token-when-using-datacollatorforlanguagemodeling-fr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id, tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='microsoft/Phi-3.5-mini-instruct', vocab_size=32000, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '<|endoftext|>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t32000: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32001: AddedToken(\"<|assistant|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32002: AddedToken(\"<|placeholder1|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32003: AddedToken(\"<|placeholder2|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32004: AddedToken(\"<|placeholder3|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32005: AddedToken(\"<|placeholder4|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32006: AddedToken(\"<|system|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32007: AddedToken(\"<|end|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32008: AddedToken(\"<|placeholder5|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32009: AddedToken(\"<|placeholder6|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32010: AddedToken(\"<|user|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Data Processing\n",
    "##################\n",
    "def clean_mesages(messages, updated_system_prompt):\n",
    "    messages_clean = []\n",
    "    for m in messages:\n",
    "        role = m['from']\n",
    "        content = m['value']\n",
    "        if role == 'human':\n",
    "            role = 'user'\n",
    "        elif role == 'gpt':\n",
    "            role = 'assistant'\n",
    "        elif role == 'system':\n",
    "            content = updated_system_prompt\n",
    "        messages_clean.append({'role': role, 'content': content})\n",
    "    return messages_clean\n",
    "\n",
    "def apply_chat_template(\n",
    "    example,\n",
    "    tokenizer,\n",
    "):\n",
    "    updated_system_prompt = example[\"system_prompt\"]\n",
    "    messages_init = example[\"conversations\"]\n",
    "    messages = clean_mesages(messages_init, updated_system_prompt)\n",
    "    example[\"text\"] = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=False).strip('\\n')\n",
    "    return example\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = ds['train']\n",
    "column_names = list(train_dataset.features)\n",
    "\n",
    "processed_train_dataset = train_dataset.map(\n",
    "    apply_chat_template,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    num_proc=10,\n",
    "    desc=\"Applying chat template to train_sft\",\n",
    ")\n",
    "\n",
    "# shuffle the dataset\n",
    "processed_train_dataset = processed_train_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '3faaadfc-6ccc-47ee-9b54-77b5a333a73b',\n",
       " 'conversations': [{'from': 'system',\n",
       "   'value': 'You are a helpful assistant, with no access to external functions.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'Transform these sentences into a passive voice\\nThey are singing a song.'},\n",
       "  {'from': 'gpt', 'value': 'A song is being sung by them.'},\n",
       "  {'from': 'human', 'value': 'What is passive voice and why is it used?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'In passive voice, the subject of a sentence receives the action instead of performing it. Passive voice is used to shift focus from the doer (subject) of an action to the receiver (object). It can also be used to make writing more formal or objective.'},\n",
       "  {'from': 'human',\n",
       "   'value': 'How can I identify passive voice in a sentence?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Passive voice can be identified by looking for a form of \"to be\" (is, was, are, were, be, being, been) followed by a past participle verb (usually ending in -ed or -en) and the absence of an explicit doer (or when the doer is introduced with \"by\"). For example, \"The cake was baked by John\" is in passive voice because \"was\" is a form of \"to be,\" \"baked\" is a past participle verb, and \"John\" is introduced with \"by.\"'},\n",
       "  {'from': 'human',\n",
       "   'value': 'When should I avoid using passive voice in my writing?'},\n",
       "  {'from': 'gpt',\n",
       "   'value': 'Passive voice can be overused and make writing sound unnatural or unclear. Active voice is generally preferred for clear, direct communication. However, there are some cases where passive voice may be appropriate or necessary, such as when the doer is unknown, unimportant, or purposely left out. Additionally, passive voice can be used to vary sentence structure and create emphasis on the object or receiver of an action.'}],\n",
       " 'tools': 'null',\n",
       " 'category': 'Language and Linguistics',\n",
       " 'subcategory': None,\n",
       " 'task': 'English Grammar and Syntax',\n",
       " 'source': 'Glaive',\n",
       " 'system_prompt': \"You are a function calling AI model.\\nYou are provided with function signatures within <tools></tools> XML tags.\\nYou may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools:\\n<tools>\\n[{'type': 'function', 'function': {'name': 'get_definition', 'description': 'Get the definition of a word', 'parameters': {'type': 'object', 'properties': {'word': {'type': 'string', 'description': 'The word to get the definition of'}}, 'required': ['word']}}}, {'type': 'function', 'function': {'name': 'calculate_loan_payment', 'description': 'Calculate the monthly loan payment', 'parameters': {'type': 'object', 'properties': {'principal': {'type': 'number', 'description': 'The principal amount of the loan'}, 'interest_rate': {'type': 'number', 'description': 'The annual interest rate'}, 'loan_term': {'type': 'integer', 'description': 'The loan term in years'}}, 'required': ['principal', 'interest_rate', 'loan_term']}}}]\\n</tools>\\nUse the following pydantic model json schema for each tool call you will make: \\n{'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}\\nFor each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\\n<tool_call>\\n{tool_call}\\n</tool_call>\\n\",\n",
       " 'text': '<|system|>\\nYou are a function calling AI model.\\nYou are provided with function signatures within <tools></tools> XML tags.\\nYou may call one or more functions to assist with the user query. Don\\'t make assumptions about what values to plug into functions. Here are the available tools:\\n<tools>\\n[{\\'type\\': \\'function\\', \\'function\\': {\\'name\\': \\'get_definition\\', \\'description\\': \\'Get the definition of a word\\', \\'parameters\\': {\\'type\\': \\'object\\', \\'properties\\': {\\'word\\': {\\'type\\': \\'string\\', \\'description\\': \\'The word to get the definition of\\'}}, \\'required\\': [\\'word\\']}}}, {\\'type\\': \\'function\\', \\'function\\': {\\'name\\': \\'calculate_loan_payment\\', \\'description\\': \\'Calculate the monthly loan payment\\', \\'parameters\\': {\\'type\\': \\'object\\', \\'properties\\': {\\'principal\\': {\\'type\\': \\'number\\', \\'description\\': \\'The principal amount of the loan\\'}, \\'interest_rate\\': {\\'type\\': \\'number\\', \\'description\\': \\'The annual interest rate\\'}, \\'loan_term\\': {\\'type\\': \\'integer\\', \\'description\\': \\'The loan term in years\\'}}, \\'required\\': [\\'principal\\', \\'interest_rate\\', \\'loan_term\\']}}}]\\n</tools>\\nUse the following pydantic model json schema for each tool call you will make: \\n{\\'title\\': \\'FunctionCall\\', \\'type\\': \\'object\\', \\'properties\\': {\\'arguments\\': {\\'title\\': \\'Arguments\\', \\'type\\': \\'object\\'}, \\'name\\': {\\'title\\': \\'Name\\', \\'type\\': \\'string\\'}}, \\'required\\': [\\'arguments\\', \\'name\\']}\\nFor each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\\n<tool_call>\\n{tool_call}\\n</tool_call>\\n<|end|>\\n<|user|>\\nTransform these sentences into a passive voice\\nThey are singing a song.<|end|>\\n<|assistant|>\\nA song is being sung by them.<|end|>\\n<|user|>\\nWhat is passive voice and why is it used?<|end|>\\n<|assistant|>\\nIn passive voice, the subject of a sentence receives the action instead of performing it. Passive voice is used to shift focus from the doer (subject) of an action to the receiver (object). It can also be used to make writing more formal or objective.<|end|>\\n<|user|>\\nHow can I identify passive voice in a sentence?<|end|>\\n<|assistant|>\\nPassive voice can be identified by looking for a form of \"to be\" (is, was, are, were, be, being, been) followed by a past participle verb (usually ending in -ed or -en) and the absence of an explicit doer (or when the doer is introduced with \"by\"). For example, \"The cake was baked by John\" is in passive voice because \"was\" is a form of \"to be,\" \"baked\" is a past participle verb, and \"John\" is introduced with \"by.\"<|end|>\\n<|user|>\\nWhen should I avoid using passive voice in my writing?<|end|>\\n<|assistant|>\\nPassive voice can be overused and make writing sound unnatural or unclear. Active voice is generally preferred for clear, direct communication. However, there are some cases where passive voice may be appropriate or necessary, such as when the doer is unknown, unimportant, or purposely left out. Additionally, passive voice can be used to vary sentence structure and create emphasis on the object or receiver of an action.<|end|>\\n<|endoftext|>'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are a function calling AI model.\n",
      "You are provided with function signatures within <tools></tools> XML tags.\n",
      "You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools:\n",
      "<tools>\n",
      "[{'type': 'function', 'function': {'name': 'search_wikipedia', 'description': 'Search for a topic on Wikipedia', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The search query'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'search_recipes', 'description': 'Search for recipes based on ingredients and dietary restrictions', 'parameters': {'type': 'object', 'properties': {'ingredients': {'type': 'array', 'items': {'type': 'string'}, 'description': 'The ingredients available'}, 'dietary_restrictions': {'type': 'array', 'items': {'type': 'string'}, 'description': 'The dietary restrictions to consider'}}, 'required': ['ingredients', 'dietary_restrictions']}}}]\n",
      "</tools>\n",
      "Use the following pydantic model json schema for each tool call you will make: \n",
      "{'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}\n",
      "For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
      "<tool_call>\n",
      "{tool_call}\n",
      "</tool_call>\n",
      "<|end|>\n",
      "<|user|>\n",
      "Can you tell me about the Eiffel Tower?<|end|>\n",
      "<|assistant|>\n",
      "<tool_call>\n",
      "{'name': 'search_wikipedia', 'arguments': {'query': 'Eiffel Tower'}}\n",
      "</tool_call><|end|>\n",
      "<|assistant|>\n",
      "The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower. Constructed from 1887 to 1889 as the entrance to the 1889 World's Fair, it is a global cultural icon of France and one of the most recognizable structures in the world.<|end|>\n",
      "<|user|>\n",
      "That's interesting. Can you tell me about Gustave Eiffel?<|end|>\n",
      "<|assistant|>\n",
      "<tool_call>\n",
      "{'name': 'search_wikipedia', 'arguments': {'query': 'Gustave Eiffel'}}\n",
      "</tool_call><|end|>\n",
      "<|assistant|>\n",
      "Alexandre Gustave Eiffel was a French civil engineer. A graduate of École Centrale Paris, he made his name building various bridges for the French railway network, most famously the Garabit viaduct. He is best known for the world-famous Eiffel Tower, built for the 1889 Universal Exposition in Paris, and his contribution to building the Statue of Liberty in New York.<|end|>\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(processed_train_dataset['text'][13])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfect assistant example:\n",
    "\n",
    "<|im_start|>system\n",
    "You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags.You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions.Here are the available tools:<tools> [{'type': 'function', 'function': {'name': 'create_todo', 'description': 'Create a new todo item', 'parameters': {'type': 'object', 'properties': {'title': {'type': 'string', 'description': 'The title of the todo item'}, 'description': {'type': 'string', 'description': 'The description of the todo item'}}, 'required': ['title']}}}, {'type': 'function', 'function': {'name': 'create_invoice', 'description': 'Create a new invoice', 'parameters': {'type': 'object', 'properties': {'client': {'type': 'string', 'description': 'The name of the client'}, 'items': {'type': 'array', 'items': {'type': 'object', 'properties': {'description': {'type': 'string', 'description': 'The description of the item'}, 'quantity': {'type': 'integer', 'description': 'The quantity of the item'}, 'price': {'type': 'number', 'description': 'The price of the item'}}, 'required': ['description', 'quantity', 'price']}, 'description': 'The list of items in the invoice'}}, 'required': ['client', 'items']}}}] </tools>Use the following pydantic model json schema for each tool call you will make: {'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "<tool_call>\n",
    "{tool_call}\n",
    "</tool_call><|im_end|>\n",
    "<|im_start|>user\n",
    "I need to create a new todo item.<|im_end|>\n",
    "<|im_start|>assistant\n",
    "Sure, I can help with that. Could you please provide me with the title and description of the todo item?<|im_end|>\n",
    "<|im_start|>user\n",
    "The title is \"Grocery Shopping\" and the description is \"Buy fruits, vegetables, and bread\".<|im_end|>\n",
    "<|im_start|>assistant\n",
    "<tool_call>\n",
    "{'name': 'create_todo', 'arguments': {'title': 'Grocery Shopping', 'description': 'Buy fruits, vegetables, and bread'}}\n",
    "</tool_call><|im_end|>\n",
    "<|im_start|>tool\n",
    "<tool_response>\n",
    "{'status': 'success', 'message': \"Todo item 'Grocery Shopping' has been created successfully.\"}\n",
    "</tool_response><|im_end|>\n",
    "<|im_start|>assistant\n",
    "Your todo item \"Grocery Shopping\" has been created successfully. It includes \"Buy fruits, vegetables, and bread\".<|im_end|>\n",
    "\n",
    "\n",
    "This todo list creation is exactly what you'd want an assistant to help with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2484a96bcac4546b293ead0c063afd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now test how this works with the existing model\n",
    "\n",
    "####################\n",
    "# Base Model Loading\n",
    "####################\n",
    "checkpoint_path = \"HuggingFaceTB/SmolLM-1.7B\"\n",
    "#checkpoint_path=\"microsoft/Phi-3.5-mini\"\n",
    "#checkpoint_path = \"microsoft/Phi-3.5-mini-instruct\"\n",
    "\n",
    "model_kwargs = dict(\n",
    "    use_cache=False,\n",
    "    trust_remote_code=True,\n",
    "#    attn_implementation=\"flash_attention_2\",  # only works on latest gpus, probably not worth it in most cases\n",
    "     torch_dtype=torch.bfloat16,\n",
    "   device_map='auto'\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path, **model_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a function calling AI model.\n",
      "You are provided with function signatures within <tools></tools> XML tags.\n",
      "You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools:\n",
      "<tools>\n",
      "[{'type': 'function', 'function': {'name': 'turn_on_lights', 'description': 'Turn the lights on', 'parameters': {}}}, {'type': 'function', 'function': {'name': 'get_news', 'description': 'Get the latest news', 'parameters': {'type': 'object', 'properties': {'category': {'type': 'string', 'description': 'The category of news, e.g. sports, politics'}}, 'required': ['category']}}}]\n",
      "</tools>\n",
      "Use the following pydantic model json schema for each tool call you will make: \n",
      "{'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}\n",
      "For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
      "<tool_call>\n",
      "{tool_call}\n",
      "</tool_call>\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "Did the nets win?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Did the nets win?\n",
      "\n",
      "You are a function calling AI model.\n",
      "You are provided with function signatures within <tools></tools> XML tags.\n",
      "You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools:\n",
      "<tools>\n",
      "[{'type': 'function', 'function': {'name': 'turn_on_lights', 'description': 'Turn the lights on', 'parameters': {}}}, {'type': 'function', 'function': {'name': 'get_news', 'description': 'Get the latest news', 'parameters': {'type': 'object', 'properties': {'category': {'type': 'string', 'description': 'The category of news, e.g. sports, politics'}}, 'required': ['category']}}}]\n",
      "</tools>\n",
      "Use the following pydantic model json schema for each tool call you will make: \n",
      "{'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', '\n",
      "<|im_start|>system\n",
      "You are a function calling AI model.\n",
      "You are provided with function signatures within <tools></tools> XML tags.\n",
      "You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools:\n",
      "<tools>\n",
      "[{'type': 'function', 'function': {'name': 'turn_on_lights', 'description': 'Turn the lights on', 'parameters': {}}}, {'type': 'function', 'function': {'name': 'get_news', 'description': 'Get the latest news', 'parameters': {'type': 'object', 'properties': {'category': {'type': 'string', 'description': 'The category of news, e.g. sports, politics'}}, 'required': ['category']}}}]\n",
      "</tools>\n",
      "Use the following pydantic model json schema for each tool call you will make: \n",
      "{'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}\n",
      "For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
      "<tool_call>\n",
      "{tool_call}\n",
      "</tool_call>\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "Did the nets win?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Did the nets win?\n",
      "\n",
      "You are a function calling AI model.\n",
      "You are provided with function signatures within <tools></tools> XML tags.\n",
      "You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools:\n",
      "<tools>\n",
      "[{'type': 'function', 'function': {'name': 'turn_on_lights', 'description': 'Turn the lights on', 'parameters': {}}}, {'type': 'function', 'function': {'name': 'get_news', 'description': 'Get the latest news', 'parameters': {'type': 'object', 'properties': {'category': {'type': 'string', 'description': 'The category of news, e.g. sports, politics'}}, 'required': ['category']}}}]\n",
      "</tools>\n",
      "Use the following pydantic model json schema for each tool call you will make: \n",
      "{'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', '<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"Did the nets win?\"\n",
    "\n",
    "#  To use as reference when creating tools in the future.\n",
    "\n",
    "available_tools = [{'type': 'function',\n",
    "  'function': {'name': 'turn_on_lights',\n",
    "   'description': 'Turn the lights on',\n",
    "    'parameters': {}}},    \n",
    " {'type': 'function',\n",
    "  'function': {'name': 'get_news',\n",
    "   'description': 'Get the latest news',\n",
    "   'parameters': {'type': 'object',\n",
    "    'properties': {'category': {'type': 'string',\n",
    "      'description': 'The category of news, e.g. sports, politics'}},\n",
    "    'required': ['category']}}}]\n",
    "\n",
    "\n",
    "system_prompt = f\"\"\"You are a function calling AI model.\n",
    "You are provided with function signatures within <tools></tools> XML tags.\n",
    "You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools:\n",
    "<tools>\n",
    "{available_tools}\n",
    "</tools>\n",
    "Use the following pydantic model json schema for each tool call you will make: \n",
    "{pydantic_schema}\n",
    "For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "<tool_call>\n",
    "{{tool_call}}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    "\n",
    "tool_calling_system_prompt = f\"\"\"<|im_start|>system\n",
    "{system_prompt}<|im_end|>\"\"\"\n",
    "tool_calling_user_prompt = f\"\"\"\n",
    "<|im_start|>user\n",
    "{user_prompt}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "tool_calling_prompt = tool_calling_system_prompt + tool_calling_user_prompt\n",
    "\n",
    "\n",
    "model.eval();\n",
    "\n",
    "input_ids = tokenizer.encode(tool_calling_prompt, return_tensors='pt')\n",
    "input_ids = input_ids.to(model.device)\n",
    "output = model.generate(input_ids, max_new_tokens=256,  do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=False, pad_token_id = tokenizer.eos_token_id)\n",
    "print(output_text)\n",
    "formatted_output_text = \"<|im_end|>\".join(output_text.split(\"<|im_end|>\")[:3]) + \"<|im_end|>\"\n",
    "print(formatted_output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "wandb.init(project=\"smollm-ft-function-calling\")\n",
    "###################\n",
    "# Hyper-parameters\n",
    "###################\n",
    "training_config = {\n",
    "    \"do_eval\": False,\n",
    "    \"learning_rate\": 5.0e-04,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"gradient_accumulation_steps\": 2,\n",
    "    \"log_level\": \"info\",\n",
    "    \"logging_steps\": 100,\n",
    "    \"logging_strategy\": \"steps\",\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"num_train_epochs\": 5,\n",
    "    \"max_steps\": -1,\n",
    "    \"output_dir\": \"./checkpoint_dir\",\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"remove_unused_columns\": True,\n",
    "    \"save_steps\": 500,\n",
    "    \"save_total_limit\": 1,\n",
    "    \"seed\": 0,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"gradient_checkpointing_kwargs\":{\"use_reentrant\": False},\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"warmup_ratio\": 0.05,\n",
    "    \"report_to\":\"wandb\"\n",
    "    }\n",
    "\n",
    "\n",
    "train_conf = TrainingArguments(**training_config)\n",
    "\n",
    "###############\n",
    "# Setup logging\n",
    "###############\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "log_level = train_conf.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "logger.info(f\"Training/evaluation parameters {train_conf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# Training\n",
    "###########\n",
    "\n",
    "model.train();\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=train_conf,\n",
    "    train_dataset=processed_train_dataset,\n",
    "    max_seq_length=2048,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    #packing=True,\n",
    ")\n",
    "train_result = trainer.train()\n",
    "metrics = train_result.metrics\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca23fd2a5184019ae72ae6a03ab4238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the model from the checkpoint\n",
    "\n",
    "# find most recently created folder in checkpoint_dir and set as checkpoint path\n",
    "#checkpoint_path = sorted(os.listdir(train_conf.output_dir))[-1]\n",
    "checkpoint_path = os.path.join('checkpoint_dir', 'checkpoint-4500')\n",
    "model_kwargs = dict(\n",
    "    use_cache=False,\n",
    "    trust_remote_code=True,\n",
    "     torch_dtype=torch.bfloat16,\n",
    "   device_map='auto'\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path, **model_kwargs)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='checkpoint_dir/checkpoint-4500', vocab_size=32000, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '<|endoftext|>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t32000: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32001: AddedToken(\"<|assistant|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32002: AddedToken(\"<|placeholder1|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32003: AddedToken(\"<|placeholder2|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32004: AddedToken(\"<|placeholder3|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32005: AddedToken(\"<|placeholder4|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32006: AddedToken(\"<|system|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32007: AddedToken(\"<|end|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32008: AddedToken(\"<|placeholder5|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32009: AddedToken(\"<|placeholder6|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32010: AddedToken(\"<|user|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Did the nets win?\"\n",
    "\n",
    "#  To use as reference when creating tools in the future.\n",
    "\n",
    "available_tools = [{'type': 'function',\n",
    "  'function': {'name': 'turn_on_lights',\n",
    "   'description': 'Turn the lights on',\n",
    "    'parameters': {}}},    \n",
    " {'type': 'function',\n",
    "  'function': {'name': 'get_news',\n",
    "   'description': 'Get the latest news',\n",
    "   'parameters': {'type': 'object',\n",
    "    'properties': {'category': {'type': 'string',\n",
    "      'description': 'The category of news, e.g. sports, politics'}},\n",
    "    'required': ['category']}}}]\n",
    "\n",
    "\n",
    "system_prompt = f\"\"\"You are a function calling AI model.\n",
    "You are provided with function signatures within <tools></tools> XML tags.\n",
    "You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools:\n",
    "<tools>\n",
    "{available_tools}\n",
    "</tools>\n",
    "Use the following pydantic model json schema for each tool call you will make: \n",
    "{pydantic_schema}\n",
    "For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "<tool_call>\n",
    "{{tool_call}}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    "\n",
    "tool_calling_system_prompt = f\"\"\"<|im_start|>system\n",
    "{system_prompt}<|im_end|>\"\"\"\n",
    "tool_calling_user_prompt = f\"\"\"\n",
    "<|im_start|>user\n",
    "{user_prompt}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "tool_calling_prompt = tool_calling_system_prompt + tool_calling_user_prompt\n",
    "\n",
    "\n",
    "model.eval();\n",
    "\n",
    "input_ids = tokenizer.encode(tool_calling_prompt, return_tensors='pt')\n",
    "input_ids = input_ids.to(model.device)\n",
    "output = model.generate(input_ids, max_new_tokens=256,  do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=False, pad_token_id = tokenizer.eos_token_id)\n",
    "#print(output_text)\n",
    "formatted_output_text = \"<|im_end|>\".join(output_text.split(\"<|im_end|>\")[:3]) + \"<|im_end|>\"\n",
    "print(formatted_output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|> You are a function calling AI model.\n",
      "You are provided with function signatures within <tools></tools> XML tags.\n",
      "You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools:\n",
      "<tools>\n",
      "[{'type': 'function', 'function': {'name': 'send_message', 'description': 'Send a message to a contact', 'parameters': {'type': 'object', 'properties': {'contact': {'type': 'string', 'description': 'The contact to send the message to'}, 'message': {'type': 'string', 'description': 'The message to send'}}, 'required': ['contact', 'message']}}}, {'type': 'function', 'function': {'name': 'get_news', 'description': 'Get the latest news', 'parameters': {'type': 'object', 'properties': {'category': {'type': 'string', 'description': 'The category of news, e.g. sports, politics'}}, 'required': ['category']}}}]\n",
      "</tools>\n",
      "Use the following pydantic model json schema for each tool call you will make: \n",
      "{'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}\n",
      "For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
      "<tool_call>\n",
      "{tool_call}\n",
      "</tool_call>\n",
      "<|end|><|user|> Send a message to John saying hi<|end|><|assistant|> John, I hope this message finds you well.<|end|>\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"Send a message to John saying hi\"\n",
    "\n",
    "#  To use as reference when creating tools in the future.\n",
    "\n",
    "available_tools = [{'type': 'function',\n",
    "  'function': {'name': 'send_message',\n",
    "   'description': 'Send a message to a contact',\n",
    "    'parameters': {'type': 'object',\n",
    "    'properties': {'contact': {'type': 'string',\n",
    "      'description': 'The contact to send the message to'},\n",
    "     'message': {'type': 'string',\n",
    "      'description': 'The message to send'}} ,\n",
    "    'required': ['contact', 'message']}}},\n",
    "\n",
    " {'type': 'function',\n",
    "  'function': {'name': 'get_news',\n",
    "   'description': 'Get the latest news',\n",
    "   'parameters': {'type': 'object',\n",
    "    'properties': {'category': {'type': 'string',\n",
    "      'description': 'The category of news, e.g. sports, politics'}},\n",
    "    'required': ['category']}}}]\n",
    "\n",
    "\n",
    "system_prompt = f\"\"\"You are a function calling AI model.\n",
    "You are provided with function signatures within <tools></tools> XML tags.\n",
    "You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools:\n",
    "<tools>\n",
    "{available_tools}\n",
    "</tools>\n",
    "Use the following pydantic model json schema for each tool call you will make: \n",
    "{pydantic_schema}\n",
    "For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "<tool_call>\n",
    "{{tool_call}}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    "\n",
    "tool_calling_system_prompt = f\"\"\"<|im_start|>system\n",
    "{system_prompt}<|im_end|>\"\"\"\n",
    "tool_calling_user_prompt = f\"\"\"\n",
    "<|im_start|>user\n",
    "{user_prompt}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "tool_calling_prompt = tool_calling_system_prompt + tool_calling_user_prompt\n",
    "\n",
    "tool_calling_prompt = tool_calling_prompt.replace(\"<|im_start|>system\", \"<|system|>\").replace(\"<|im_start|>user\", \"<|user|>\").replace(\"<|im_start|>assistant\", \"<|assistant|>\").replace(\"<|im_end|>\", \"<|end|>\")\n",
    "model.eval();\n",
    "\n",
    "input_ids = tokenizer.encode(tool_calling_prompt, return_tensors='pt')\n",
    "input_ids = input_ids.to(model.device)\n",
    "output = model.generate(input_ids, max_new_tokens=256,  do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=False, pad_token_id = tokenizer.eos_token_id)\n",
    "#print(output_text)\n",
    "formatted_output_text = \"<|im_end|>\".join(output_text.split(\"<|im_end|>\")[:3]) + \"<|im_end|>\"\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are a function calling AI model.\n",
      "You are provided with function signatures within <tools></tools> XML tags.\n",
      "You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools:\n",
      "<tools>\n",
      "[{'type': 'function', 'function': {'name': 'turn_on_lights', 'description': 'Turn the lights on in a room', 'parameters': {}}}, {'type': 'function', 'function': {'name': 'get_news', 'description': 'Get the latest news', 'parameters': {'type': 'object', 'properties': {'category': {'type': 'string', 'description': 'The category of news, e.g. sports, politics'}}, 'required': ['category']}}}]\n",
      "</tools>\n",
      "Use the following pydantic model json schema for each tool call you will make: \n",
      "{'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}\n",
      "For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
      "<tool_call>\n",
      "{tool_call}\n",
      "</tool_call>\n",
      "<|end|>\n",
      "\n",
      "<|user|>\n",
      "Did the nets win?<|end|>\n",
      "\n",
      "<|assistant|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tool_calling_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|> You are a function calling AI model.\n",
      "You are provided with function signatures within <tools></tools> XML tags.\n",
      "You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools:\n",
      "<tools>\n",
      "[{'type': 'function', 'function': {'name': 'search_wikipedia', 'description': 'Search for a topic on Wikipedia', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The search query'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'search_recipes', 'description': 'Search for recipes based on ingredients and dietary restrictions', 'parameters': {'type': 'object', 'properties': {'ingredients': {'type': 'array', 'items': {'type': 'string'}, 'description': 'The ingredients available'}, 'dietary_restrictions': {'type': 'array', 'items': {'type': 'string'}, 'description': 'The dietary restrictions to consider'}}, 'required': ['ingredients', 'dietary_restrictions']}}}]\n",
      "</tools>\n",
      "Use the following pydantic model json schema for each tool call you will make: \n",
      "{'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}\n",
      "For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
      "<tool_call>\n",
      "{tool_call}\n",
      "</tool_call>\n",
      "<|end|><|user|> Search recipes?<|end|><|assistant|> <tool_call>\n",
      "{'name': 'search_wikipedia', 'arguments': {'query': 'recipes'}}\n",
      "</tool_call><|end|>\n"
     ]
    }
   ],
   "source": [
    "test_prompt = \"\"\"<|system|>\n",
    "You are a function calling AI model.\n",
    "You are provided with function signatures within <tools></tools> XML tags.\n",
    "You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools:\n",
    "<tools>\n",
    "[{'type': 'function', 'function': {'name': 'search_wikipedia', 'description': 'Search for a topic on Wikipedia', 'parameters': {'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'The search query'}}, 'required': ['query']}}}, {'type': 'function', 'function': {'name': 'search_recipes', 'description': 'Search for recipes based on ingredients and dietary restrictions', 'parameters': {'type': 'object', 'properties': {'ingredients': {'type': 'array', 'items': {'type': 'string'}, 'description': 'The ingredients available'}, 'dietary_restrictions': {'type': 'array', 'items': {'type': 'string'}, 'description': 'The dietary restrictions to consider'}}, 'required': ['ingredients', 'dietary_restrictions']}}}]\n",
    "</tools>\n",
    "Use the following pydantic model json schema for each tool call you will make: \n",
    "{'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}\n",
    "For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "<tool_call>\n",
    "{tool_call}\n",
    "</tool_call>\n",
    "<|end|>\n",
    "<|user|>\n",
    "Search recipes?<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "\n",
    "input_ids = tokenizer.encode(test_prompt, return_tensors='pt')\n",
    "input_ids = input_ids.to(model.device)\n",
    "model.eval();\n",
    "\n",
    "output = model.generate(input_ids, max_new_tokens=256,  do_sample=False)#, pad_token_id=tokenizer.eos_token_id)\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=False)#, pad_token_id = tokenizer.eos_token_id)\n",
    "#print(output_text)\n",
    "formatted_output_text = \"<|im_end|>\".join(output_text.split(\"<|im_end|>\")[:3]) + \"<|im_end|>\"\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[32006,   887,   526,   263,   740,  5432,   319, 29902,  1904, 29889,\n",
       "            13,  3492,   526,  4944,   411,   740,  1804,  3698,  2629,   529,\n",
       "          8504,  2565,  8504, 29958,  6560,  8282, 29889,    13,  3492,  1122,\n",
       "          1246,   697,   470,   901,  3168,   304,  6985,   411,   278,  1404,\n",
       "          2346, 29889,  3872, 29915, 29873,  1207, 20813,  1048,   825,  1819,\n",
       "           304, 18665,   964,  3168, 29889,  2266,   526,   278,  3625,  8492,\n",
       "         29901,    13, 29966,  8504, 29958,    13, 29961, 10998,  1853,  2396,\n",
       "           525,  2220,   742,   525,  2220,  2396, 11117,   978,  2396,   525,\n",
       "          4478, 29918,  6011,   742,   525,  8216,  2396,   525,  7974,   363,\n",
       "           263, 11261,   373, 14109,   742,   525, 16744,  2396, 11117,  1853,\n",
       "          2396,   525,  3318,   742,   525, 11330,  2396, 11117,  1972,  2396,\n",
       "         11117,  1853,  2396,   525,  1807,   742,   525,  8216,  2396,   525,\n",
       "          1576,  2740,  2346, 29915, 11656,   525, 12403,  2396,  6024,  1972,\n",
       "          2033,   930,  1118, 11117,  1853,  2396,   525,  2220,   742,   525,\n",
       "          2220,  2396, 11117,   978,  2396,   525,  4478, 29918,  4361,  5547,\n",
       "           742,   525,  8216,  2396,   525,  7974,   363,  9522,  5547,  2729,\n",
       "           373,  2348,  1127, 10070,   322,   652,   300,   653, 25091,   742,\n",
       "           525, 16744,  2396, 11117,  1853,  2396,   525,  3318,   742,   525,\n",
       "         11330,  2396, 11117,   292,  1127, 10070,  2396, 11117,  1853,  2396,\n",
       "           525,  2378,   742,   525,  7076,  2396, 11117,  1853,  2396,   525,\n",
       "          1807, 16675,   525,  8216,  2396,   525,  1576,  2348,  1127, 10070,\n",
       "          3625, 16675,   525, 29881,  2035,   653, 29918,  5060,  4146,  1080,\n",
       "          2396, 11117,  1853,  2396,   525,  2378,   742,   525,  7076,  2396,\n",
       "         11117,  1853,  2396,   525,  1807, 16675,   525,  8216,  2396,   525,\n",
       "          1576,   652,   300,   653, 25091,   304,  2050, 29915, 11656,   525,\n",
       "         12403,  2396,  6024,   292,  1127, 10070,   742,   525, 29881,  2035,\n",
       "           653, 29918,  5060,  4146,  1080,  2033,   930,  6525,    13,   829,\n",
       "          8504, 29958,    13, 11403,   278,  1494,   282,  2941,  7716,  1904,\n",
       "          4390, 10938,   363,  1269,  5780,  1246,   366,   674,  1207, 29901,\n",
       "         29871,    13, 10998,  3257,  2396,   525,  6678,  5594,   742,   525,\n",
       "          1853,  2396,   525,  3318,   742,   525, 11330,  2396, 11117, 25699,\n",
       "          2396, 11117,  3257,  2396,   525, 26915,   742,   525,  1853,  2396,\n",
       "           525,  3318, 16675,   525,   978,  2396, 11117,  3257,  2396,   525,\n",
       "          1170,   742,   525,  1853,  2396,   525,  1807, 29915, 11656,   525,\n",
       "         12403,  2396,  6024, 25699,   742,   525,   978,  2033, 29913,    13,\n",
       "          2831,  1269,   740,  1246,   736,   263,  4390,  1203,   411,   740,\n",
       "          1024,   322,  6273,  2629,   529, 10154, 29918,  4804,  2565, 10154,\n",
       "         29918,  4804, 29958,  6560,  8282,   408,  4477, 29901,    13, 29966,\n",
       "         10154, 29918,  4804, 29958,    13, 29912, 10154, 29918,  4804, 29913,\n",
       "            13,   829, 10154, 29918,  4804, 29958,    13, 32007, 32010,  1815,\n",
       "           366,  2649,   592,  1048,   278,   382,  2593,   295, 23615, 29973,\n",
       "         32007, 32001]], device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
