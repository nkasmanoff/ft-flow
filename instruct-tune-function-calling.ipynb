{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 22.6M/22.6M [00:00<00:00, 26.5MB/s]\n",
      "Generating train split: 100%|██████████| 5209/5209 [00:00<00:00, 49245.54 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"NousResearch/hermes-function-calling-v1\", \"glaive_func_calling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'from': 'system',\n",
       "  'value': \"You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags.You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions.Here are the available tools:<tools> [{'type': 'function', 'function': {'name': 'get_stock_price', 'description': 'Get the current stock price of a company', 'parameters': {'type': 'object', 'properties': {'company': {'type': 'string', 'description': 'The name of the company'}}, 'required': ['company']}}}, {'type': 'function', 'function': {'name': 'send_email', 'description': 'Send an email to a recipient', 'parameters': {'type': 'object', 'properties': {'recipient': {'type': 'string', 'description': 'The email address of the recipient'}, 'subject': {'type': 'string', 'description': 'The subject of the email'}, 'message': {'type': 'string', 'description': 'The body of the email'}}, 'required': ['recipient', 'subject', 'message']}}}] </tools>Use the following pydantic model json schema for each tool call you will make: {'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\\n<tool_call>\\n{tool_call}\\n</tool_call>\"},\n",
       " {'from': 'human',\n",
       "  'value': 'Hey, can you tell me the current stock price of Apple?'},\n",
       " {'from': 'gpt',\n",
       "  'value': \"<tool_call>\\n{'name': 'get_stock_price', 'arguments': {'company': 'Apple'}}\\n</tool_call>\"},\n",
       " {'from': 'tool',\n",
       "  'value': \"<tool_response>\\n{'stock_price': '$150.75'}\\n</tool_response>\"},\n",
       " {'from': 'gpt', 'value': 'The current stock price of Apple is $150.75.'},\n",
       " {'from': 'human', 'value': 'What about Microsoft?'},\n",
       " {'from': 'gpt',\n",
       "  'value': \"<tool_call>\\n{'name': 'get_stock_price', 'arguments': {'company': 'Microsoft'}}\\n</tool_call>\"},\n",
       " {'from': 'tool',\n",
       "  'value': \"<tool_response>\\n{'stock_price': '$210.22'}\\n</tool_response>\"},\n",
       " {'from': 'gpt', 'value': 'The current stock price of Microsoft is $210.22.'},\n",
       " {'from': 'human', 'value': 'And Google?'},\n",
       " {'from': 'gpt',\n",
       "  'value': \"<tool_call>\\n{'name': 'get_stock_price', 'arguments': {'company': 'Google'}}\\n</tool_call>\"},\n",
       " {'from': 'tool',\n",
       "  'value': \"<tool_response>\\n{'stock_price': '$2,820.46'}\\n</tool_response>\"},\n",
       " {'from': 'gpt', 'value': 'The current stock price of Google is $2,820.46.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train']['conversations'][10]\n",
    "\n",
    "# Some changes to make based on this to match LLM FT paradigm\n",
    "\n",
    "# from and value should be replaced with role and content (chat format)\n",
    "\n",
    "# replace human with user, gpt with assistant\n",
    "# check to see if tool call can be a special token or not\n",
    "\n",
    "# is the way assisant follows tool response what we want? \n",
    "\n",
    "# are the list of tools available fixed for all system prompts? \n",
    "# can we possibly enhance and add more, and create synthetic data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# Tokenizer Loading\n",
    "###################\n",
    "\n",
    "checkpoint_path = \"HuggingFaceTB/SmolLM-360M-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "tokenizer.model_max_length = 2048\n",
    "tokenizer.pad_token = \"<|endoftext|>\"  # note this is specific to smollm\n",
    "tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token )\n",
    "tokenizer.padding_side = 'right'\n",
    "# https://stackoverflow.com/questions/76446228/setting-padding-token-as-eos-token-when-using-datacollatorforlanguagemodeling-fr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying chat template to train_sft (num_proc=10): 100%|██████████| 5209/5209 [00:00<00:00, 16621.47 examples/s]\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# Data Processing\n",
    "##################\n",
    "def clean_mesages(messages):\n",
    "    messages_clean = []\n",
    "    for m in messages:\n",
    "        role = m['from']\n",
    "        content = m['value']\n",
    "        if role == 'human':\n",
    "            role = 'user'\n",
    "        elif role == 'gpt':\n",
    "            role = 'assistant'\n",
    "        messages_clean.append({'role': role, 'content': content})\n",
    "    return messages_clean\n",
    "\n",
    "def apply_chat_template(\n",
    "    example,\n",
    "    tokenizer,\n",
    "):\n",
    "\n",
    "    messages_init = example[\"conversations\"]\n",
    "    messages = clean_mesages(messages_init)\n",
    "    example[\"text\"] = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=False).strip('\\n')\n",
    "    return example\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = ds['train']\n",
    "column_names = list(train_dataset.features)\n",
    "\n",
    "processed_train_dataset = train_dataset.map(\n",
    "    apply_chat_template,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    num_proc=10,\n",
    "    desc=\"Applying chat template to train_sft\",\n",
    ")\n",
    "\n",
    "# shuffle the dataset\n",
    "processed_train_dataset = processed_train_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant, with no access to external functions.<|im_end|>\n",
      "<|im_start|>user\n",
      "Transform these sentences into a passive voice\n",
      "They are singing a song.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "A song is being sung by them.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is passive voice and why is it used?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "In passive voice, the subject of a sentence receives the action instead of performing it. Passive voice is used to shift focus from the doer (subject) of an action to the receiver (object). It can also be used to make writing more formal or objective.<|im_end|>\n",
      "<|im_start|>user\n",
      "How can I identify passive voice in a sentence?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Passive voice can be identified by looking for a form of \"to be\" (is, was, are, were, be, being, been) followed by a past participle verb (usually ending in -ed or -en) and the absence of an explicit doer (or when the doer is introduced with \"by\"). For example, \"The cake was baked by John\" is in passive voice because \"was\" is a form of \"to be,\" \"baked\" is a past participle verb, and \"John\" is introduced with \"by.\"<|im_end|>\n",
      "<|im_start|>user\n",
      "When should I avoid using passive voice in my writing?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Passive voice can be overused and make writing sound unnatural or unclear. Active voice is generally preferred for clear, direct communication. However, there are some cases where passive voice may be appropriate or necessary, such as when the doer is unknown, unimportant, or purposely left out. Additionally, passive voice can be used to vary sentence structure and create emphasis on the object or receiver of an action.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(processed_train_dataset['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags.You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions.Here are the available tools:<tools> [{'type': 'function', 'function': {'name': 'create_todo', 'description': 'Create a new todo item', 'parameters': {'type': 'object', 'properties': {'title': {'type': 'string', 'description': 'The title of the todo item'}, 'description': {'type': 'string', 'description': 'The description of the todo item'}}, 'required': ['title']}}}, {'type': 'function', 'function': {'name': 'create_invoice', 'description': 'Create a new invoice', 'parameters': {'type': 'object', 'properties': {'client': {'type': 'string', 'description': 'The name of the client'}, 'items': {'type': 'array', 'items': {'type': 'object', 'properties': {'description': {'type': 'string', 'description': 'The description of the item'}, 'quantity': {'type': 'integer', 'description': 'The quantity of the item'}, 'price': {'type': 'number', 'description': 'The price of the item'}}, 'required': ['description', 'quantity', 'price']}, 'description': 'The list of items in the invoice'}}, 'required': ['client', 'items']}}}] </tools>Use the following pydantic model json schema for each tool call you will make: {'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
      "<tool_call>\n",
      "{tool_call}\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "I need to create a new todo item.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Sure, I can help with that. Could you please provide me with the title and description of the todo item?<|im_end|>\n",
      "<|im_start|>user\n",
      "The title is \"Grocery Shopping\" and the description is \"Buy fruits, vegetables, and bread\".<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<tool_call>\n",
      "{'name': 'create_todo', 'arguments': {'title': 'Grocery Shopping', 'description': 'Buy fruits, vegetables, and bread'}}\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>tool\n",
      "<tool_response>\n",
      "{'status': 'success', 'message': \"Todo item 'Grocery Shopping' has been created successfully.\"}\n",
      "</tool_response><|im_end|>\n",
      "<|im_start|>assistant\n",
      "Your todo item \"Grocery Shopping\" has been created successfully. It includes \"Buy fruits, vegetables, and bread\".<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(processed_train_dataset['text'][10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfect assistant example:\n",
    "\n",
    "<|im_start|>system\n",
    "You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags.You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions.Here are the available tools:<tools> [{'type': 'function', 'function': {'name': 'create_todo', 'description': 'Create a new todo item', 'parameters': {'type': 'object', 'properties': {'title': {'type': 'string', 'description': 'The title of the todo item'}, 'description': {'type': 'string', 'description': 'The description of the todo item'}}, 'required': ['title']}}}, {'type': 'function', 'function': {'name': 'create_invoice', 'description': 'Create a new invoice', 'parameters': {'type': 'object', 'properties': {'client': {'type': 'string', 'description': 'The name of the client'}, 'items': {'type': 'array', 'items': {'type': 'object', 'properties': {'description': {'type': 'string', 'description': 'The description of the item'}, 'quantity': {'type': 'integer', 'description': 'The quantity of the item'}, 'price': {'type': 'number', 'description': 'The price of the item'}}, 'required': ['description', 'quantity', 'price']}, 'description': 'The list of items in the invoice'}}, 'required': ['client', 'items']}}}] </tools>Use the following pydantic model json schema for each tool call you will make: {'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "<tool_call>\n",
    "{tool_call}\n",
    "</tool_call><|im_end|>\n",
    "<|im_start|>user\n",
    "I need to create a new todo item.<|im_end|>\n",
    "<|im_start|>assistant\n",
    "Sure, I can help with that. Could you please provide me with the title and description of the todo item?<|im_end|>\n",
    "<|im_start|>user\n",
    "The title is \"Grocery Shopping\" and the description is \"Buy fruits, vegetables, and bread\".<|im_end|>\n",
    "<|im_start|>assistant\n",
    "<tool_call>\n",
    "{'name': 'create_todo', 'arguments': {'title': 'Grocery Shopping', 'description': 'Buy fruits, vegetables, and bread'}}\n",
    "</tool_call><|im_end|>\n",
    "<|im_start|>tool\n",
    "<tool_response>\n",
    "{'status': 'success', 'message': \"Todo item 'Grocery Shopping' has been created successfully.\"}\n",
    "</tool_response><|im_end|>\n",
    "<|im_start|>assistant\n",
    "Your todo item \"Grocery Shopping\" has been created successfully. It includes \"Buy fruits, vegetables, and bread\".<|im_end|>\n",
    "\n",
    "\n",
    "This todo list creation is exactly what you'd want an assistant to help with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now test how this works with the existing model\n",
    "\n",
    "####################\n",
    "# Base Model Loading\n",
    "####################\n",
    "checkpoint_path = \"HuggingFaceTB/SmolLM-360M\"\n",
    "model_kwargs = dict(\n",
    "    use_cache=False,\n",
    "    trust_remote_code=True,\n",
    "#    attn_implementation=\"flash_attention_2\",  # only works on latest gpus, probably not worth it in most cases\n",
    "     torch_dtype=torch.bfloat16,\n",
    "   device_map='cpu'\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path, **model_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags.You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions.Here are the available tools:<tools> [{'type': 'function', 'function': {'name': 'create_todo', 'description': 'Create a new todo item', 'parameters': {'type': 'object', 'properties': {'title': {'type': 'string', 'description': 'The title of the todo item'}, 'description': {'type': 'string', 'description': 'The description of the todo item'}}, 'required': ['title']}}}, {'type': 'function', 'function': {'name': 'create_invoice', 'description': 'Create a new invoice', 'parameters': {'type': 'object', 'properties': {'client': {'type': 'string', 'description': 'The name of the client'}, 'items': {'type': 'array', 'items': {'type': 'object', 'properties': {'description': {'type': 'string', 'description': 'The description of the item'}, 'quantity': {'type': 'integer', 'description': 'The quantity of the item'}, 'price': {'type': 'number', 'description': 'The price of the item'}}, 'required': ['description', 'quantity', 'price']}, 'description': 'The list of items in the invoice'}}, 'required': ['client', 'items']}}}] </tools>Use the following pydantic model json schema for each tool call you will make: {'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
      "<tool_call>\n",
      "{tool_call}\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "I need to create a new todo item with the title 'Buy groceries'..<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"I need to create a new todo item with the title 'Buy groceries'.\"\n",
    "tool_calling_system_prompt = \"\"\"<|im_start|>system\n",
    "You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags.You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions.Here are the available tools:<tools> [{'type': 'function', 'function': {'name': 'create_todo', 'description': 'Create a new todo item', 'parameters': {'type': 'object', 'properties': {'title': {'type': 'string', 'description': 'The title of the todo item'}, 'description': {'type': 'string', 'description': 'The description of the todo item'}}, 'required': ['title']}}}, {'type': 'function', 'function': {'name': 'create_invoice', 'description': 'Create a new invoice', 'parameters': {'type': 'object', 'properties': {'client': {'type': 'string', 'description': 'The name of the client'}, 'items': {'type': 'array', 'items': {'type': 'object', 'properties': {'description': {'type': 'string', 'description': 'The description of the item'}, 'quantity': {'type': 'integer', 'description': 'The quantity of the item'}, 'price': {'type': 'number', 'description': 'The price of the item'}}, 'required': ['description', 'quantity', 'price']}, 'description': 'The list of items in the invoice'}}, 'required': ['client', 'items']}}}] </tools>Use the following pydantic model json schema for each tool call you will make: {'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "<tool_call>\n",
    "{tool_call}\n",
    "</tool_call><|im_end|>\"\"\"\n",
    "\n",
    "tool_calling_user_prompt = f\"\"\"\n",
    "<|im_start|>user\n",
    "{user_prompt}.<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "tool_calling_prompt = tool_calling_system_prompt + tool_calling_user_prompt\n",
    "\n",
    "print(tool_calling_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags.You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions.Here are the available tools:<tools> [{'type': 'function', 'function': {'name': 'create_todo', 'description': 'Create a new todo item', 'parameters': {'type': 'object', 'properties': {'title': {'type': 'string', 'description': 'The title of the todo item'}, 'description': {'type': 'string', 'description': 'The description of the todo item'}}, 'required': ['title']}}}, {'type': 'function', 'function': {'name': 'create_invoice', 'description': 'Create a new invoice', 'parameters': {'type': 'object', 'properties': {'client': {'type': 'string', 'description': 'The name of the client'}, 'items': {'type': 'array', 'items': {'type': 'object', 'properties': {'description': {'type': 'string', 'description': 'The description of the item'}, 'quantity': {'type': 'integer', 'description': 'The quantity of the item'}, 'price': {'type': 'number', 'description': 'The price of the item'}}, 'required': ['description', 'quantity', 'price']}, 'description': 'The list of items in the invoice'}}, 'required': ['client', 'items']}}}] </tools>Use the following pydantic model json schema for each tool call you will make: {'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
      "<tool_call>\n",
      "{tool_call}\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "I need to create a new todo item with the title 'Buy groceries'..<|im_end|>\n",
      "<|im_start|>assistant\n",
      "I need to create a new todo item with the title 'Buy groceries'..\n",
      " I need to create a new todo item with the title 'Buy groceries'..\n",
      " I need to create a new todo item with the title 'Buy groceries'..\n",
      " I need to create a new todo item with the title 'Buy groceries'..\n",
      " I need to create a new todo item with the title 'Buy groceries'..\n",
      " I need to create a new todo item with the title 'Buy groceries'..\n",
      " I need to create a new todo item with the title 'Buy groceries'..\n",
      " I need to create a new todo item with the title 'Buy groceries'..\n",
      " I need to create a new todo item with the title 'Buy groceries'..\n",
      " I need to create a new todo item with the title 'Buy groceries'..\n",
      " I need to create a new todo item with the title 'Buy groceries'..\n",
      " I need to create a new todo item with the title 'Buy groceries'..\n",
      " I need to create a new todo item with the title 'Buy groceries'..\n",
      " I need to create a new todo item with the title 'Buy groceries'..\n",
      " I need to create<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "model.eval();\n",
    "\n",
    "input_ids = tokenizer.encode(tool_calling_prompt, return_tensors='pt')\n",
    "input_ids = input_ids.to(model.device)\n",
    "output = model.generate(input_ids, max_new_tokens=256,  do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=False, pad_token_id = tokenizer.eos_token_id)\n",
    "formatted_output_text = \"<|im_end|>\".join(output_text.split(\"<|im_end|>\")[:3]) + \"<|im_end|>\"\n",
    "print(formatted_output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "wandb.init(project=\"smollm-ft\")\n",
    "###################\n",
    "# Hyper-parameters\n",
    "###################\n",
    "training_config = {\n",
    "    \"do_eval\": False,\n",
    "    \"learning_rate\": 5.0e-04,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"gradient_accumulation_steps\": 2,\n",
    "    \"log_level\": \"info\",\n",
    "    \"logging_steps\": 100,\n",
    "    \"logging_strategy\": \"steps\",\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"max_steps\": -1,\n",
    "    \"output_dir\": \"./checkpoint_dir\",\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"remove_unused_columns\": True,\n",
    "    \"save_steps\": 500,\n",
    "    \"save_total_limit\": 1,\n",
    "    \"seed\": 0,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"gradient_checkpointing_kwargs\":{\"use_reentrant\": False},\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"warmup_ratio\": 0.05,\n",
    "    \"report_to\":\"wandb\"\n",
    "    }\n",
    "\n",
    "\n",
    "train_conf = TrainingArguments(**training_config)\n",
    "\n",
    "###############\n",
    "# Setup logging\n",
    "###############\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "log_level = train_conf.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "logger.info(f\"Training/evaluation parameters {train_conf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# Training\n",
    "###########\n",
    "\n",
    "model.train();\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=train_conf,\n",
    "    train_dataset=processed_train_dataset,\n",
    "    max_seq_length=2048,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    #packing=True,\n",
    ")\n",
    "train_result = trainer.train()\n",
    "metrics = train_result.metrics\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the checkpoint\n",
    "\n",
    "# find most recently created folder in checkpoint_dir and set as checkpoint path\n",
    "checkpoint_path = sorted(os.listdir(train_conf.output_dir))[-1]\n",
    "checkpoint_path = os.path.join(train_conf.output_dir, checkpoint_path)\n",
    "model_kwargs = dict(\n",
    "    use_cache=False,\n",
    "    trust_remote_code=True,\n",
    "     torch_dtype=torch.bfloat16,\n",
    "   device_map='auto'\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path, **model_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"I need to create a new todo item with the title 'Buy groceries'.\"\n",
    "tool_calling_system_prompt = \"\"\"<|im_start|>system\n",
    "You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags.You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions.Here are the available tools:<tools> [{'type': 'function', 'function': {'name': 'create_todo', 'description': 'Create a new todo item', 'parameters': {'type': 'object', 'properties': {'title': {'type': 'string', 'description': 'The title of the todo item'}, 'description': {'type': 'string', 'description': 'The description of the todo item'}}, 'required': ['title']}}}, {'type': 'function', 'function': {'name': 'create_invoice', 'description': 'Create a new invoice', 'parameters': {'type': 'object', 'properties': {'client': {'type': 'string', 'description': 'The name of the client'}, 'items': {'type': 'array', 'items': {'type': 'object', 'properties': {'description': {'type': 'string', 'description': 'The description of the item'}, 'quantity': {'type': 'integer', 'description': 'The quantity of the item'}, 'price': {'type': 'number', 'description': 'The price of the item'}}, 'required': ['description', 'quantity', 'price']}, 'description': 'The list of items in the invoice'}}, 'required': ['client', 'items']}}}] </tools>Use the following pydantic model json schema for each tool call you will make: {'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "<tool_call>\n",
    "{tool_call}\n",
    "</tool_call><|im_end|>\"\"\"\n",
    "\n",
    "tool_calling_user_prompt = f\"\"\"\n",
    "<|im_start|>user\n",
    "{user_prompt}.<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "tool_calling_prompt = tool_calling_system_prompt + tool_calling_user_prompt\n",
    "\n",
    "print(tool_calling_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "action-annotator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
