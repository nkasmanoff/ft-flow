{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import transformers\n",
    "from trl import SFTTrainer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "import os\n",
    "import json\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets transformers trl wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"NousResearch/hermes-function-calling-v1\", \"glaive_func_calling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "tools_list = []\n",
    "for tool in ds['train']['tools']:\n",
    "    if tool == 'null':\n",
    "        tools_list.append(None)\n",
    "        continue\n",
    "\n",
    "    # str fixes to convert to dict\n",
    "    tool = tool.replace('true','True')\n",
    "    tool = tool.replace('false','False')\n",
    "    tool = tool.replace('null','None')\n",
    "    tools_list.append(literal_eval(tool))   \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydantic_schema = \"\"\"{'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}\"\"\"\n",
    "from tqdm import tqdm\n",
    "\n",
    "system_prompts = []\n",
    "for i in tqdm(range(len(ds['train']))):\n",
    "    if ds['train']['tools'][i] == 'null':\n",
    "        system_prompts.append(system_prompt)\n",
    "    else:\n",
    "        available_tools = tools_list[i]\n",
    "        system_prompt = f\"\"\"You are a function calling AI model.\n",
    "You are provided with function signatures within <tools></tools> XML tags.\n",
    "You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools:\n",
    "<tools>\n",
    "{available_tools}\n",
    "</tools>\n",
    "Use the following pydantic model json schema for each tool call you will make: \n",
    "{pydantic_schema}\n",
    "For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "<tool_call>\n",
    "{{tool_call}}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    "        system_prompts.append(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  To use as reference when creating tools in the future.\n",
    "\n",
    "custom_tools_list = [{'type': 'function',\n",
    "  'function': {'name': 'turn_on_lights',\n",
    "   'description': 'Turn the lights on',\n",
    "   # no parameters required\n",
    "    'parameters': {}}},    \n",
    " {'type': 'function',\n",
    "  'function': {'name': 'get_news',\n",
    "   'description': 'Get the latest news',\n",
    "   'parameters': {'type': 'object',\n",
    "    'properties': {'category': {'type': 'string',\n",
    "      'description': 'The category of news, e.g. sports, politics'}},\n",
    "    'required': ['category']}}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column to dataset called system_prompt\n",
    "ds['train'] = ds['train'].add_column('system_prompt', system_prompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['train'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['train']['conversations'][1122]\n",
    "\n",
    "# Some changes to make based on this to match LLM FT paradigm\n",
    "\n",
    "# from and value should be replaced with role and content (chat format)\n",
    "\n",
    "# replace human with user, gpt with assistant\n",
    "# check to see if tool call can be a special token or not\n",
    "\n",
    "# is the way assisant follows tool response what we want? \n",
    "\n",
    "# are the list of tools available fixed for all system prompts? \n",
    "# can we possibly enhance and add more, and create synthetic data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# Tokenizer Loading\n",
    "###################\n",
    "\n",
    "checkpoint_path = \"HuggingFaceTB/SmolLM-360M-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "tokenizer.model_max_length = 2048\n",
    "tokenizer.pad_token = \"<|endoftext|>\"  # note this is specific to smollm\n",
    "tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token )\n",
    "tokenizer.padding_side = 'right'\n",
    "# https://stackoverflow.com/questions/76446228/setting-padding-token-as-eos-token-when-using-datacollatorforlanguagemodeling-fr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.eos_token_id, tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Data Processing\n",
    "##################\n",
    "def clean_mesages(messages, updated_system_prompt):\n",
    "    messages_clean = []\n",
    "    for m in messages:\n",
    "        role = m['from']\n",
    "        content = m['value']\n",
    "        if role == 'human':\n",
    "            role = 'user'\n",
    "        elif role == 'gpt':\n",
    "            role = 'assistant'\n",
    "        elif role == 'system':\n",
    "            content = updated_system_prompt\n",
    "        messages_clean.append({'role': role, 'content': content})\n",
    "    return messages_clean\n",
    "\n",
    "def apply_chat_template(\n",
    "    example,\n",
    "    tokenizer,\n",
    "):\n",
    "    updated_system_prompt = example[\"system_prompt\"]\n",
    "    messages_init = example[\"conversations\"]\n",
    "    messages = clean_mesages(messages_init, updated_system_prompt)\n",
    "    example[\"text\"] = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=False).strip('\\n')\n",
    "    return example\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = ds['train']\n",
    "column_names = list(train_dataset.features)\n",
    "\n",
    "processed_train_dataset = train_dataset.map(\n",
    "    apply_chat_template,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    num_proc=10,\n",
    "    desc=\"Applying chat template to train_sft\",\n",
    ")\n",
    "\n",
    "# shuffle the dataset\n",
    "processed_train_dataset = processed_train_dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed_train_dataset['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_dataset['text'][11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfect assistant example:\n",
    "\n",
    "<|im_start|>system\n",
    "You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags.You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions.Here are the available tools:<tools> [{'type': 'function', 'function': {'name': 'create_todo', 'description': 'Create a new todo item', 'parameters': {'type': 'object', 'properties': {'title': {'type': 'string', 'description': 'The title of the todo item'}, 'description': {'type': 'string', 'description': 'The description of the todo item'}}, 'required': ['title']}}}, {'type': 'function', 'function': {'name': 'create_invoice', 'description': 'Create a new invoice', 'parameters': {'type': 'object', 'properties': {'client': {'type': 'string', 'description': 'The name of the client'}, 'items': {'type': 'array', 'items': {'type': 'object', 'properties': {'description': {'type': 'string', 'description': 'The description of the item'}, 'quantity': {'type': 'integer', 'description': 'The quantity of the item'}, 'price': {'type': 'number', 'description': 'The price of the item'}}, 'required': ['description', 'quantity', 'price']}, 'description': 'The list of items in the invoice'}}, 'required': ['client', 'items']}}}] </tools>Use the following pydantic model json schema for each tool call you will make: {'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "<tool_call>\n",
    "{tool_call}\n",
    "</tool_call><|im_end|>\n",
    "<|im_start|>user\n",
    "I need to create a new todo item.<|im_end|>\n",
    "<|im_start|>assistant\n",
    "Sure, I can help with that. Could you please provide me with the title and description of the todo item?<|im_end|>\n",
    "<|im_start|>user\n",
    "The title is \"Grocery Shopping\" and the description is \"Buy fruits, vegetables, and bread\".<|im_end|>\n",
    "<|im_start|>assistant\n",
    "<tool_call>\n",
    "{'name': 'create_todo', 'arguments': {'title': 'Grocery Shopping', 'description': 'Buy fruits, vegetables, and bread'}}\n",
    "</tool_call><|im_end|>\n",
    "<|im_start|>tool\n",
    "<tool_response>\n",
    "{'status': 'success', 'message': \"Todo item 'Grocery Shopping' has been created successfully.\"}\n",
    "</tool_response><|im_end|>\n",
    "<|im_start|>assistant\n",
    "Your todo item \"Grocery Shopping\" has been created successfully. It includes \"Buy fruits, vegetables, and bread\".<|im_end|>\n",
    "\n",
    "\n",
    "This todo list creation is exactly what you'd want an assistant to help with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now test how this works with the existing model\n",
    "\n",
    "####################\n",
    "# Base Model Loading\n",
    "####################\n",
    "checkpoint_path = \"HuggingFaceTB/SmolLM-360M\"\n",
    "model_kwargs = dict(\n",
    "    use_cache=False,\n",
    "    trust_remote_code=True,\n",
    "#    attn_implementation=\"flash_attention_2\",  # only works on latest gpus, probably not worth it in most cases\n",
    "     torch_dtype=torch.bfloat16,\n",
    "   device_map='auto'\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path, **model_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"I need to create a new todo item with the title 'Buy groceries'.\"\n",
    "tool_calling_system_prompt = \"\"\"<|im_start|>system\n",
    "You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags. You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions.Here are the available tools:<tools> [{'type': 'function', 'function': {'name': 'create_todo', 'description': 'Create a new todo item', 'parameters': {'type': 'object', 'properties': {'title': {'type': 'string', 'description': 'The title of the todo item'}, 'description': {'type': 'string', 'description': 'The description of the todo item'}}, 'required': ['title']}}}, {'type': 'function', 'function': {'name': 'create_invoice', 'description': 'Create a new invoice', 'parameters': {'type': 'object', 'properties': {'client': {'type': 'string', 'description': 'The name of the client'}, 'items': {'type': 'array', 'items': {'type': 'object', 'properties': {'description': {'type': 'string', 'description': 'The description of the item'}, 'quantity': {'type': 'integer', 'description': 'The quantity of the item'}, 'price': {'type': 'number', 'description': 'The price of the item'}}, 'required': ['description', 'quantity', 'price']}, 'description': 'The list of items in the invoice'}}, 'required': ['client', 'items']}}}] </tools>Use the following pydantic model json schema for each tool call you will make: {'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "<tool_call>\n",
    "{tool_call}\n",
    "</tool_call><|im_end|>\"\"\"\n",
    "\n",
    "tool_calling_user_prompt = f\"\"\"\n",
    "<|im_start|>user\n",
    "{user_prompt}.<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "tool_calling_prompt = tool_calling_system_prompt + tool_calling_user_prompt\n",
    "\n",
    "print(tool_calling_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();\n",
    "\n",
    "input_ids = tokenizer.encode(tool_calling_prompt, return_tensors='pt')\n",
    "input_ids = input_ids.to(model.device)\n",
    "output = model.generate(input_ids, max_new_tokens=256,  do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=False, pad_token_id = tokenizer.eos_token_id)\n",
    "print(output_text)\n",
    "formatted_output_text = \"<|im_end|>\".join(output_text.split(\"<|im_end|>\")[:3]) + \"<|im_end|>\"\n",
    "#print(formatted_output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "wandb.init(project=\"smollm-ft-function-calling\")\n",
    "###################\n",
    "# Hyper-parameters\n",
    "###################\n",
    "training_config = {\n",
    "    \"do_eval\": False,\n",
    "    \"learning_rate\": 5.0e-05,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"gradient_accumulation_steps\": 2,\n",
    "    \"log_level\": \"info\",\n",
    "    \"logging_steps\": 100,\n",
    "    \"logging_strategy\": \"steps\",\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"num_train_epochs\": 5,\n",
    "    \"max_steps\": -1,\n",
    "    \"output_dir\": \"./checkpoint_dir\",\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"remove_unused_columns\": True,\n",
    "    \"save_steps\": 500,\n",
    "    \"save_total_limit\": 1,\n",
    "    \"seed\": 0,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"gradient_checkpointing_kwargs\":{\"use_reentrant\": False},\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"warmup_ratio\": 0.05,\n",
    "    \"report_to\":\"wandb\"\n",
    "    }\n",
    "\n",
    "\n",
    "train_conf = TrainingArguments(**training_config)\n",
    "\n",
    "###############\n",
    "# Setup logging\n",
    "###############\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "log_level = train_conf.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "logger.info(f\"Training/evaluation parameters {train_conf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# Training\n",
    "###########\n",
    "\n",
    "model.train();\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=train_conf,\n",
    "    train_dataset=processed_train_dataset,\n",
    "    max_seq_length=2048,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    #packing=True,\n",
    ")\n",
    "train_result = trainer.train()\n",
    "metrics = train_result.metrics\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the checkpoint\n",
    "\n",
    "# find most recently created folder in checkpoint_dir and set as checkpoint path\n",
    "checkpoint_path = sorted(os.listdir(train_conf.output_dir))[-1]\n",
    "checkpoint_path = os.path.join(train_conf.output_dir, checkpoint_path)\n",
    "model_kwargs = dict(\n",
    "    use_cache=False,\n",
    "    trust_remote_code=True,\n",
    "     torch_dtype=torch.bfloat16,\n",
    "   device_map='auto'\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path, **model_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Who are you?\"\n",
    "tool_calling_system_prompt = \"\"\"<|im_start|>system\n",
    "You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags.You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions.Here are the available tools:<tools> [{'type': 'function', 'function': {'name': 'create_todo', 'description': 'Create a new todo item', 'parameters': {'type': 'object', 'properties': {'title': {'type': 'string', 'description': 'The title of the todo item'}, 'description': {'type': 'string', 'description': 'The description of the todo item'}}, 'required': ['title']}}}, {'type': 'function', 'function': {'name': 'create_invoice', 'description': 'Create a new invoice', 'parameters': {'type': 'object', 'properties': {'client': {'type': 'string', 'description': 'The name of the client'}, 'items': {'type': 'array', 'items': {'type': 'object', 'properties': {'description': {'type': 'string', 'description': 'The description of the item'}, 'quantity': {'type': 'integer', 'description': 'The quantity of the item'}, 'price': {'type': 'number', 'description': 'The price of the item'}}, 'required': ['description', 'quantity', 'price']}, 'description': 'The list of items in the invoice'}}, 'required': ['client', 'items']}}}] </tools>Use the following pydantic model json schema for each tool call you will make: {'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']}For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "<tool_call>\n",
    "{tool_call}\n",
    "</tool_call><|im_end|>\"\"\"\n",
    "\n",
    "tool_calling_user_prompt = f\"\"\"\n",
    "<|im_start|>user\n",
    "{user_prompt}.<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "tool_calling_prompt = tool_calling_system_prompt + tool_calling_user_prompt\n",
    "\n",
    "print(tool_calling_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();\n",
    "\n",
    "input_ids = tokenizer.encode(tool_calling_prompt, return_tensors='pt')\n",
    "input_ids = input_ids.to(model.device)\n",
    "output = model.generate(input_ids, max_new_tokens=256,  do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=False, pad_token_id = tokenizer.eos_token_id)\n",
    "formatted_output_text = \"<|im_end|>\".join(output_text.split(\"<|im_end|>\")[:3]) + \"<|im_end|>\"\n",
    "print(formatted_output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
