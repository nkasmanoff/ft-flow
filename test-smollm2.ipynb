{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruct tuning the model\n",
    "\n",
    "This notebook draws heavily a similar one done for the [phi3](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct/blob/main/sample_finetune.py) model. \n",
    "\n",
    "The difference here is that this will focus on a model's full fine-tuning process, work for going from a base model to a new insruction model, and should work for almost any model on HuggingFace.\n",
    "\n",
    "At the end of the notebook are the steps to save this as a gguf format which will allow for fast and easy inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import transformers\n",
    "from trl import SFTTrainer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "import os\n",
    "import json\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "####################\n",
    "# Base Model Loading\n",
    "####################\n",
    "checkpoint_path = \"HuggingFaceTB/SmolLM2-360M-Instruct\"\n",
    "model_kwargs = dict(\n",
    "    use_cache=False,\n",
    "    trust_remote_code=True,\n",
    "#    attn_implementation=\"flash_attention_2\",  # only works on latest gpus, probably not worth it in most cases\n",
    "     torch_dtype=torch.bfloat16,\n",
    "   device_map='auto'\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path, **model_kwargs)\n",
    "\n",
    "\n",
    "###################\n",
    "# Tokenizer Loading\n",
    "###################\n",
    "\n",
    "checkpoint_path = \"HuggingFaceTB/SmolLM2-360M-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "tokenizer.model_max_length = 2048\n",
    "tokenizer.pad_token = \"<|endoftext|>\"  # note this is specific to smollm\n",
    "tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token )\n",
    "tokenizer.padding_side = 'right'\n",
    "# https://stackoverflow.com/questions/76446228/setting-padding-token-as-eos-token-when-using-datacollatorforlanguagemodeling-fr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "I have 45 pills. Sofie dose is 1 pill in morning and half pill at night. How long will this last<|im_end|>\n",
      "<|im_start|>assistant\n",
      "To determine how long the medication will last, we need to calculate the total dose and then divide it by the dose Sophie takes at night.\n",
      "\n",
      "The medication is 45 pills, and Sophie takes half of it at night. So, Sophie takes 45/2 = 22.5 pills at night.\n",
      "\n",
      "Now, we need to divide the total dose by Sophie's dose at night. The total dose is 45 pills, and Sophie takes 22.5 pills at night, so the total dose is 45/22.5 = 1.96 pills.\n",
      "\n",
      "Since we can't have a fraction of a pill, we'll round down to the nearest whole number. However, since Sophie takes half of the total dose, we can't have exactly half of a pill. But we can say that the medication will last approximately 1.96 pills.\n",
      "\n",
      "So, the medication will last approximately 1.96 pills.<|im_end|><|im_end|>\n"
     ]
    }
   ],
   "source": [
    "model.eval();\n",
    "prompt = \"\"\"I have 45 pills. Sofie dose is 1 pill in morning and half pill at night. How long will this last\"\"\"\n",
    "system_prompt = \"<|im_start|>system\\nYou are Pi-Card, the Raspberry Pi voice assistant.<|im_end|>\\n\"\n",
    "prompt = f\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "input_ids = input_ids.to(model.device)\n",
    "output = model.generate(input_ids, max_new_tokens=256,  do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=False, pad_token_id = tokenizer.eos_token_id)\n",
    "formatted_output_text = \"<|im_end|>\".join(output_text.split(\"<|im_end|>\")[:3]) + \"<|im_end|>\"\n",
    "print(formatted_output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are Pi-Card, the Raspberry Pi voice assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "I have 45 pills. Sofie dose is 1 pill in morning and half pill at night. How long will this last<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Sofie's daily dose is a 1500mg pill that can be broken into 4 parts. You are left with 45 pills. So you will have 45 pills left. To know how long their \"pill\" will last, you can divide 45 pills by the total dose of 1500mg and then divide 1 by 4 parts, which is then dividing 1 by 4. \n",
      "\n",
      "However, a more precise measure of 1500mg is in milligrams. The dose was 1 pill in morning and half a pill at night, so in terms of a milligram of medication, this is half of the 1500mg pill. Then to divide a half of 1500mg by the number of doses Sofie takes in a day, which gives you 1500 divided by half, that is 750mg each dose, divided by 2, you get a divide of 375mg per dose, but that's per dose, so it's half of that if that was the answer 375 per dose. But it actually is halved of the whole dose that goes each time so that's halved, is half of 750 (half of 1500). And if you divide that in half for the two doses of each, that is half that, you get 750 divided by 2, and that's halved of that also. But more accurately, let me multiply the half and the half of it together and that would be .5*.5 =.5, or half and another half is 0.5 half is of the half, but it is the other half the half is of five, so then it would be 0.5*five is five divided by two that would be five divided by two, that is half and then it's another time, but we'd also divide that one second time. But we've still doubled half of half already.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
